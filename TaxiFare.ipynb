{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TaxiFare Jupyter Notebook Analysis\n",
    "The dataset encompasses taxi fare data from 2015-2016 across the USA, featuring over 7 million rows and exceeding 10 GB in size. \n",
    "\n",
    "Typically, PySpark is utilized for its RDD API and in-memory computation capabilities, which enhances performance for large-scale data processing. \n",
    "However, for initial ETL and data exploration, starting with pandas in a batch mode can be beneficial to visually understand the data before scaling up with Spark.\n",
    "This project prepares the data for potential machine learning applications, although it does not implement any machine learning models or standardization processes directly.\n",
    "\n",
    "\n",
    "## 📦 Package Installation\n",
    "- **Pyspark**: Ensuring that PySpark is available for processing large datasets using Spark's capabilities.\n",
    "  ```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abdullah\\desktop\\task5\\enh\\.conda\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Library Imports\n",
    "- Importing essential libraries for data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import keras \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pyspark.sql.functions import count, year, month, dayofmonth, col, to_timestamp,when,  mean, stddev, min, max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Spark Session Initialization\n",
    "- Configuring Spark to efficiently process and analyze large data volumes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL with PySpark\") \\\n",
    "    .config(\"spark.driver.memory\", \"5g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 Data Reading and Processing\n",
    "- Code to load and parse taxi fare data from a CSV file using Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df15_1 = spark.read.csv(\"S:/Data/Us_taxi_fare/yellow_tripdata_2015-01.csv\", header=True, inferSchema=True)\n",
    "df15_2 = spark.read.csv(\"S:/Data/Us_taxi_fare/yellow_tripdata_2015-02.csv\", header=True, inferSchema=True)\n",
    "df15_3 = spark.read.csv(\"S:/Data/Us_taxi_fare/yellow_tripdata_2015-03.csv\", header=True, inferSchema=True)\n",
    "df16_1 = spark.read.csv(\"S:/Data/Us_taxi_fare/yellow_tripdata_2016-01.csv\", header=True, inferSchema=True)   \n",
    "df16_2 = spark.read.csv(\"S:/Data/Us_taxi_fare/yellow_tripdata_2016-02.csv\", header=True, inferSchema=True)\n",
    "df16_3 = spark.read.csv(\"S:/Data/Us_taxi_fare/yellow_tripdata_2016-03.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df15_1.union(df15_2)  \\\n",
    "                     .union(df15_3) \\\n",
    "                     .union(df16_1) \\\n",
    "                     .union(df16_2) \\\n",
    "                     .union(df16_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------------+-----------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|  pickup_latitude|RateCodeID|store_and_fwd_flag| dropoff_longitude| dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+-----------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       2| 2015-01-15 19:05:39|  2015-01-15 19:23:42|              1|         1.59|  -73.993896484375| 40.7501106262207|         1|                 N|-73.97478485107422|40.75061798095703|           1|       12.0|  1.0|    0.5|      3.25|         0.0|                  0.3|       17.05|\n",
      "|       1| 2015-01-10 20:33:38|  2015-01-10 20:53:28|              1|          3.3|-74.00164794921875| 40.7242431640625|         1|                 N|-73.99441528320312|40.75910949707031|           1|       14.5|  0.5|    0.5|       2.0|         0.0|                  0.3|        17.8|\n",
      "|       1| 2015-01-10 20:33:38|  2015-01-10 20:43:41|              1|          1.8|-73.96334075927734|40.80278778076172|         1|                 N|-73.95182037353516|40.82441329956055|           2|        9.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        10.8|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 20:35:31|              1|          0.5|-74.00908660888672|40.71381759643555|         1|                 N|-74.00432586669922|40.71998596191406|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+-----------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, VendorID: string, passenger_count: string, trip_distance: string, pickup_longitude: string, pickup_latitude: string, RateCodeID: string, store_and_fwd_flag: string, dropoff_longitude: string, dropoff_latitude: string, payment_type: string, fare_amount: string, extra: string, mta_tax: string, tip_amount: string, tolls_amount: string, improvement_surcharge: string, total_amount: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RateCodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       0|                   0|                    0|              0|            0|               0|              0|         0|                 0|                0|               0|           0|          0|    0|      0|         0|           0|                    3|           0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|VendorID|   Count|\n",
      "+--------+--------+\n",
      "|       1|34575927|\n",
      "|       2|38475048|\n",
      "+--------+--------+\n",
      "\n",
      "+---------------+--------+\n",
      "|passenger_count|   Count|\n",
      "+---------------+--------+\n",
      "|              1|51890118|\n",
      "|              6| 2516993|\n",
      "|              3| 2944683|\n",
      "|              5| 3967367|\n",
      "|              9|      87|\n",
      "|              4| 1392887|\n",
      "|              2|10312593|\n",
      "|              0|   26011|\n",
      "|              7|     125|\n",
      "|              8|     111|\n",
      "+---------------+--------+\n",
      "\n",
      "+----------+--------+\n",
      "|RateCodeID|   Count|\n",
      "+----------+--------+\n",
      "|         1|71296899|\n",
      "|         6|     730|\n",
      "|         3|  113597|\n",
      "|         5|  220462|\n",
      "|         4|   27213|\n",
      "|         2| 1389960|\n",
      "|        99|    2114|\n",
      "+----------+--------+\n",
      "\n",
      "+------------------+--------+\n",
      "|store_and_fwd_flag|   Count|\n",
      "+------------------+--------+\n",
      "|                 Y|  535118|\n",
      "|                 N|72515857|\n",
      "+------------------+--------+\n",
      "\n",
      "+------------+--------+\n",
      "|payment_type|   Count|\n",
      "+------------+--------+\n",
      "|           1|47293209|\n",
      "|           3|  246607|\n",
      "|           4|   82604|\n",
      "|           2|25428545|\n",
      "|           5|      10|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_count = df.groupBy(\"VendorID\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()\n",
    "df_count = df.groupBy(\"passenger_count\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()\n",
    "df_count = df.groupBy(\"RateCodeID\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()\n",
    "df_count = df.groupBy(\"store_and_fwd_flag\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()\n",
    "df_count = df.groupBy(\"payment_type\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data that has a tiny amount has been renamed and grouped into a bigger group for better analysis and representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn(\"payment_type\", col(\"payment_type\").cast(\"string\"))\n",
    "df = df.withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"string\"))\n",
    "\n",
    "df = df.replace([\"5\", \"4\", \"3\"], [\"other\", \"other\", \"other\"], \"payment_type\")\n",
    "df = df.replace(\"0\", \"1\", \"passenger_count\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data has been separated so it's easier to know the different months and days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"tpep_pickup_datetime\", to_timestamp(col(\"tpep_pickup_datetime\")))\n",
    "df = df.withColumn(\"tpep_dropoff_datetime\", to_timestamp(col(\"tpep_dropoff_datetime\")))\n",
    "\n",
    "\n",
    "df = df.withColumn(\"year\", year(col(\"tpep_pickup_datetime\")))\n",
    "df = df.withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "df = df.withColumn(\"day\", dayofmonth(col(\"tpep_pickup_datetime\")))\n",
    "df = df.withColumn(\"seconds_difference\", F.unix_timestamp(\"tpep_dropoff_datetime\") - F.unix_timestamp(\"tpep_pickup_datetime\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|   Count|\n",
      "+----+--------+\n",
      "|2015|38551116|\n",
      "|2016|34499859|\n",
      "+----+--------+\n",
      "\n",
      "+-----+--------+\n",
      "|month|   Count|\n",
      "+-----+--------+\n",
      "|    1|23655844|\n",
      "|    2|23832570|\n",
      "|    3|25562561|\n",
      "+-----+--------+\n",
      "\n",
      "+---+-------+\n",
      "|day|  Count|\n",
      "+---+-------+\n",
      "| 31|1705541|\n",
      "| 28|2484395|\n",
      "| 26|2298971|\n",
      "| 27|2233707|\n",
      "| 12|2565592|\n",
      "| 22|2413852|\n",
      "|  1|2249622|\n",
      "| 13|2622211|\n",
      "|  6|2470265|\n",
      "| 16|2439664|\n",
      "|  3|2328611|\n",
      "| 20|2559295|\n",
      "|  5|2393572|\n",
      "| 19|2520545|\n",
      "| 15|2464061|\n",
      "| 17|2450408|\n",
      "|  9|2379458|\n",
      "|  4|2325266|\n",
      "|  8|2381373|\n",
      "| 23|2150286|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_count = df.groupBy(\"year\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()\n",
    "df_count = df.groupBy(\"month\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()\n",
    "df_count = df.groupBy(\"day\").agg(count(\"*\").alias(\"Count\"))\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"extra\",\"mta_tax\",\"tip_amount\",\"tolls_amount\",\"improvement_surcharge\",\"total_amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📉 Statistical Analysis\n",
    "- Calculating basic statistics for key metrics such as fare amounts and trip distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------fare_amount---------\n",
      "+-----------------+------------------+---+------+\n",
      "|             mean|            stddev|min|   max|\n",
      "+-----------------+------------------+---+------+\n",
      "|14.75088588513609|10.744981087843685|3.1|999.98|\n",
      "+-----------------+------------------+---+------+\n",
      "\n",
      "--------seconds_difference---------\n",
      "+-----------------+-----------------+---+-----+\n",
      "|             mean|           stddev|min|  max|\n",
      "+-----------------+-----------------+---+-----+\n",
      "|963.1136963720166|637.4226150348796| 61|28794|\n",
      "+-----------------+-----------------+---+-----+\n",
      "\n",
      "--------trip_distance---------\n",
      "+------------------+------------------+----+-----+\n",
      "|              mean|            stddev| min|  max|\n",
      "+------------------+------------------+----+-----+\n",
      "|3.6439254534677517|3.8568471274377227|1.01|828.1|\n",
      "+------------------+------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--------fare_amount---------\")\n",
    "stats = df.select(\n",
    "    mean(col(\"fare_amount\")).alias(\"mean\"),\n",
    "    stddev(col(\"fare_amount\")).alias(\"stddev\"),\n",
    "    min(col(\"fare_amount\")).alias(\"min\"),\n",
    "    max(col(\"fare_amount\")).alias(\"max\")\n",
    ")\n",
    "stats.show()\n",
    "\n",
    "print(\"--------seconds_difference---------\")\n",
    "stats = df.select(\n",
    "    mean(col(\"seconds_difference\")).alias(\"mean\"),\n",
    "    stddev(col(\"seconds_difference\")).alias(\"stddev\"),\n",
    "    min(col(\"seconds_difference\")).alias(\"min\"),\n",
    "    max(col(\"seconds_difference\")).alias(\"max\")\n",
    ")\n",
    "stats.show()\n",
    "\n",
    "print(\"--------trip_distance---------\")\n",
    "stats = df.select(\n",
    "    mean(col(\"trip_distance\")).alias(\"mean\"),\n",
    "    stddev(col(\"trip_distance\")).alias(\"stddev\"),\n",
    "    min(col(\"trip_distance\")).alias(\"min\"),\n",
    "    max(col(\"trip_distance\")).alias(\"max\")\n",
    ")\n",
    "stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "|   89|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(df[\"fare_amount\"] > 1000)\n",
    "\n",
    "# Count the number of rows in the filtered DataFrame\n",
    "df_count = df_filtered.agg(count(\"*\").alias(\"Count\"))\n",
    "\n",
    "# Show the result\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "|  162|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(df[\"trip_distance\"] > 1000)\n",
    "\n",
    "# Count the number of rows in the filtered DataFrame\n",
    "df_count = df_filtered.agg(count(\"*\").alias(\"Count\"))\n",
    "\n",
    "# Show the result\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Data Filtering\n",
    "- Filtering data to remove unlikely and extreme values, improving the reliability of further analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where((col(\"fare_amount\") < 1000) & (col(\"fare_amount\") > 3)) ## $3.00 initial charge for a taxi fare in the states\n",
    "df = df.where((col(\"seconds_difference\") > 60) & (col(\"seconds_difference\") < 28800)) ## from 1 min up to 8 hours\n",
    "df = df.where((col(\"trip_distance\") > 1) & (col(\"trip_distance\") < 1000)) ## from 1 distance up to 1000 hours\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
